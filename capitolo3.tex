\label{capitolo3}
\section{Architetture per l'analisi dei dati}
La tecnologia delle basi di dati è finalizzata principalmente alla gestione efficente di dati in linea (OLTP). Tramite questa tecnologia le imprese accumulano grandi moli di dati relativi alla loro gestione. Questi dati possono rivelarsi utili per la pianificazione e il supporto alle decisioni.\\
Per anni si è trascurato l'aspetto informativo dei dati supponendo che i meccanismi e i linguaggi utilizzati per il trattamento dei dati in linea fossero capaci di soddisfare le esigenze di analisi. Questo risulta in parte vero in quanto SQL è si un linguaggio adatto alla gestione e l'interrogazione di questi dati, ma risulta di difficile ottimizzazione, non adatto ad utenti no informatici ed inoltre è assai difficile ottimizzare un'applicazione affinche essa possa essere utilizzata sia per le transizioni in linea e per l'analisi dei dati.\\
Negli anni Novanta con l'avvento della tecnologia distribuita e lo sviluppo delle reti si sono evoluti specifiche architetture per l'analisi dei dati chiamate OLAP supportate da una specifica architettura la \emph{data warehouse} nella quale vengono raccolti tutti i dati.
\subsection{Architettura di una data warehouse}
Una data warehouse ha caratteristiche pe
culiari che la distinguono dalle altre basi di dati:
\begin{itemize}
\item è una \emph{base di dati integrata}. I dati provengono da diverse sorgenti informative preesistenti.
\item \emph{Contiene informazioni di caratter storico/temporale}. Mentre infatti le basi di dati OLTP mantengono il valore corrente delle informazioni nelle DW è contenuta tutta la cronologia dell'informazione.
\item \emph{Contiene dati in forma aggregata}. Le principali attività di analisi si basano su informazioni ottenute aggregando i dati disponibili rispetto opportune coordinate.
\item \emph{Ha un esistenza autonoma}. Il data warehouse è mantenuto fisicamente separato dalle sorgenti informative
\item \emph{è una base di dati fuori linea}. I meccanismi di importazione dei dati sono di tipo asincrono e periodico.
\end{itemize}

Un architettura adatta a soddisfare queste caratteristiche è composta dai seguenti componenti:
\begin{itemize}
\item Le \emph{sorgenti} dei dati o \emph{data source} I dati vengono estratti da uno o più sistemi preesistenti nel sistema informativo aziendale o da fonti esterne anche non gestito tramite DBMS.
\item Il \emph{data warehouse server} è il sistema dedicato alla gestione della DW; memorizza i dati mediante opportune strutture fisiche  e realizza in modo efficente le integrazioni complesse. Permette operazioni speciali di \emph{roll up, drill down, data cube}. Molto spesso è formato da sottosistemi realizzati per specifiche esigenze detti \emph{data mart}
\item Un \emph{sistema di alimentazione}. Consiste in una serie di strumenti ETL (\emph{Extract, Transform, Load}) che svolgono le seguenti attività di base:
\begin{itemize}
\item L'\emph{estrazione} dei dati dalle sorgenti. Dopo il popolamento iniziale il processo di estrazione è tipicamente incrementale
\item La \emph{pulizzia} dei dati che ha loscopo di analizzare la correttezza dei dati prima dell'inserimento nella data warehouse.
\item La \emph{trasformazione} dei dati. Questo processo predispone i dati all'uso operativo svolgendo operazioni di riconciliazione delle eterogeneità nelle varie sorgenti informative.
\item Il \emph{caricamento} dei dati nella data warehouse. Questa operazione avviene quando il DW non è utilizzato e può procedere accquisendo tutti i dati; oppure i dati vengono allineati in modo incrementale propagano le modifiche fatte sulla base di dati
\end{itemize}
\item Alcuni strumenti di \emph{analisi} che consentono di effettuare analisi sui dati presenti nella DW e si distinguono in:
\begin{itemize}
\item analisi multidimensionale che consiste in operazioni di aggregazione e disgregazione lungo opportune dimensioni.
\item \emph{data minning} che consente di ricavare informazioni "nascoste" dai dati
\end{itemize}
\end{itemize}
\subsection{Rappresentazine multidimensionale dei dati}
Il modello multidimensionale dei dati è basato su tre concetti base: il fatto, la misura e la dimensione.\\
Un \emph{fatto} è un concetto del sistema informativo sul quale ha senso svolgere un processo di analisi orientato al supporto di decisioni. Una \emph{misura} è invece una proprietà atomica di un fatto che intendiamo analizzare (un attributo numerico). Infine una \emph{dimensione} è una particolare prospettiva lungo la quale l'analisi di un fatto può essere effettuata. I valori possibili di una dimensione sono detti \emph{membri}.\\
Di seguito un esempio schematico
\begin{center}
\begin{verbatim}
fatto: Vendite;
misure: quantità,incasso;
dimensione: articolo, periodo di tempo, luogo;
\end{verbatim}
\end{center}

Le dimensioni vengono tipicamente organizzate in gerarchie di \emph{livelli di aggregazione} ad esempio la dimensione "luogo" potrebbe essere aggregata in "città$\rightarrow$provincia$\rightarrow$regione".\\
Un'\emph{istanza} di un fatto assegna ad ogni possibile combinazione di membri un valore per ciascuna misura del fatto.
\subsubsection{Operazione nel modello multidimensionale}
Le più note operazioni che si possono applicare al modello multidimensionale sono \emph{slice-and-dice, roll-up} e il \emph{drill-down}.\\
L'operazione di \emph{slice-and-dice} consiste nella semplice selezione di un sottoinsieme di membri; ad esempio le vendite di un certo tipo di prodotto in una città o negozio precisi.\\
L'operazione di \emph{roll-up} consiste in un aggregazione dei dati di un cubo seguita dall'applicazione di una funzione aggregativa. Esistono due tipologie di aggregazione, la prima consiste nel salire di livello in una gerarchia, oppure si elimina un'intera dimensione del cubo e aggregando lungo la dimensione eliminata.\\
Il \emph{drill-down} è l'operazione inversa del roll-up consiste cioè nell'aggiungere dettaglio alle dimensioni presenti scendendo nella gerarchia delle dimensioni.
\subsection{Realizzazione di uan data warehouse}
Per realizzare una data warehouse esistono due soluzioni alternative:
\begin{itemize}
\item La prima consiste nell'uso di una tecnologia relazionale opportunamenta adattata ed estesa, i dati vengono memorizzati in tabelle e le istruzioni di analisi vengono tradotte in SQL. Questo tipo di sistema viene detto ROLAP (\emph{Relational OLAP}).
\item La seconda soluzione memorizza i dati direttamente in maniera multidimensionale. Tali sistemi si dicono MOLAP (\emph{Multidimensional OLAP}).
\end{itemize}
\subsubsection{Rappresentazione relazionale di una data warehouse}
In una relazione ROLAP i dati di un fatto multidimesionale sono organizzati secondo una semplice struttura relazionale detto \emph{schema a stella}.
Lo schema a stella ha una struttura molto semplice ed è composta da:
\begin{itemize}
\item una relazione principale detta \emph{tabella dei fatti} che memorizza le istanzze di un fatto.
\item varie relazioni ausiliarie chiamate \emph{tabelle delle dimensioni} che memorizzano i membri delle dimensioni associate ad un fatto
\item un insieme di vincoli di integrità referenziale ognuno dei quali collega un attributo della tabella dei fatti a una tabella delle dimensioni.
\end{itemize}
Esistono alcune caratteristiche distinguibili in tuttti gli schemi a stella, distinguiamo quelle che riguardano la tabella dei fatti e quelle che riguardano quelle dimensione.
\begin{itemize}
\item Tabella dei fatti:
	\begin{itemize}
\item ha una chiave composta da attributi che sono riferimenti a chiavi delle tabelle dimensione;
\item gli attributi presentano misure del fatto e sono solitamente numerici;
\item soddisfa la forma normale di Boyce-Codd;
	\end{itemize}
\item Tabella delle dimensioni.
	\begin{itemize}
\item hanno una chiave semplice;
\item gli attributi rappresentano i livelli di una dimensione o qualche loro proprietà;
\item sono generalmente \emph{denormalizzate}.
	\end{itemize}
\end{itemize}
\subsection{Progettazione di una data warehouse}
La progettazione di una data warehouse prevede l'esecuzione di quattro fasi principali ognuna delle quali suddivisa in sotto-fasi.
\paragraph{Dati di ingresso} Lo svolgimento della metodologia richiede la specifica di informazioni di ingresso e gli schemi delle sorgenti informative. I requisiti sono una descrizione delle esigenze aziendali di analisi.\\
Gli schemi descrivono la struttura delle basi di dati disponibili con la relativa documentazione di supporto.
\paragraph{Analisi dei dati di ingresso} La prima fase consiste in un'analisi dei dati a disposizione basati sulla correlazione tra requisiti e sorgenti informative al fine di individuare le sorgenti più adatte e le loro proprietà.
Il prodotto finale della fase di analisi è costituito da uno schema concettuale per ciascuna sorgente informativa selezionata corredato dall'opportuna documentazione di supporto.
\paragraph{Integrazione} Questa fase consiste nella fusione dei dati presenti nelle varie sorgenti in un'unica base di dati globale che fornisce una visione unificata dell'intero patrimonio informativo aziendale. L'approccio è orientato alla risoluzione dei conflitti esistenti nei vari schemi tra rappresentazioni diverse degli stessi concetti.
\paragraph{Progettazione della Data Warehouse} Questa fase prevede l'effettivo progetto della DW; si possono seguire due strade: la prima definita \emph{top-down} e la seconda chiamata \emph{bottom-up}.\\
Nella prima si sviluppa la DW azziendale e poi da essa si ricavano i vari \emph{data mart}; nella seconda invece si parte dalla realizzazione dei data mart e il data warehouse si ottiene in maniera incrementale. L'approccio più diffuso è quello bottom-up in quanto implica uno sforzo e un costo di realizzazione ridotto.\\
Prima di tutto si stabiliscono alcune dimensioni di riferimento che possono essere utili per l'analisi. Si può procedere poi a una progettazione a livello concettuale e poi a livello logico traducendo lo schema concettuale in uno schema che dipende dalla tecnologia scelta. Lo schema concettuale però parte, a differenza della progettazione di una base di dati classica, dallo schema ottenuto in fase di integrazione.\\
Dallo schema di integrazione si ricavano i fatti interessanti per l'analisi che possono essere un insieme di aspetti oppure un'entità a se stante.
A questo punto si procede individuando le dimensioni dei fatti individuati. A questo punto si passa ad una ristrutturazione delle schema E-R nel quale i fatti corrispondono, nella maggior parte dei casi ad entità. Inoltre all'interno di una dimensione è molto utile rappresentare esplicitamente i vari livelli di aggregazione.\\
A questo punto si può procedere con la progettazione logica e ragionare in termini di sistema che si è deciso di adottare (ROLAP o MOLAP).\\
Alla fine si completa con la progettazione fisica della DW nella quale si definiscono le strutture disiche di accesso con i relativi parametri.
\subsection{Data mining}
Il termine \emph{data mining} viene utilizzato per indicare tecniche di analisi volte ad estrarre informazioni dai dati che non si otterrebbero con i metodi classici di analisi.
\subsubsection{Il processo data mining}
Il processo di data mining viene anche detto \emph{knowledge discovery on database (KDD)} e ha come obiettivo l'estrazione di informazioni che siano: valide con un certo grado di incertezza, precedentemente sconosciute, potenzialmente utili al supporto di decisioni.\\
Il processo opera sui dati applicando opportuni algoritmi ed è in grado di restituire espressioni che descrivono in maniera sintetica e comprensibile le informazioni estratte. Queste espressioni vengono chiamate \emph{pattern}.
Il processo di datamining procede in maniera iterativa seguendo queste fasi:
\begin{enumerate}
\item \emph{Comprensione del dominio.} è impossibile estrarre informazioni utili se non si sviluppa una buona comprensione del dominio nel quale si opera.
\item \emph{Preparazione del set di dati}. Richiede l'individuazione dei dati sui quali applicare il processo di data mining.
\item \emph{Scoperta dei pattern.} Consiste nell'applicazione del processo di data mining al set di dati in modo da estrarre pattern dai dati.
\item \emph{Valutazione dei pattern}. Consiste nel trarre implicazioni applicative dai pattern scoperti.
\item \emph{Utilizzo dei risultati}. Consiste nell'interpretare i pattern scoperti e prendere decisioni operative basate su tale interpretazione.
\end{enumerate}
\subsubsection{Problemi di data mining} 
Anche se ogni applicazione presenta problemi specifici esistono alcune classi di problemi che si ripresentano ad agni applicazione.
\paragraph{Regole di associazione} Le regole di associazione si applicano a datti descritti mediante una tabella relazionale partizionata tramite clausula di raggruppamento.\\ 
Più precisamente una regola di associazione consta di una premessa e una conseguenza e ha la forma $premessa\rightarrow conseguenza$.
E\' possibile definire in modo preciso le probabilità relative alle regole di associazione. Si usano a tale scopo:
\begin{itemize}
\item il \emph{supporto} ovvero la probabilità che in una transizione siano presenti sia la premessa che la conseguenza.
\item la \emph{confidenza} che è la probabilità che in una transizione in cui è presente la premessa sia presente anche la conseguenza.
\end{itemize}
Il supporto misura l'importanza di una regola mentre la confidenza ne misura l'affidabilità.
\paragraph{Classificazione} La classificazione mira alla catologazione di un fenomeno in un insieme di classi predefinite. Il \emph{classificatore} è un algoritmo che svolge la classificazione; viene costruito automaticamente partendo da un insieme di dati di prova e viene poi applicato per la classificazione di fenomeni generici; essi si presentano classicamente come alberi di decisione dove i nodi sono associati dei predicati che consentono di prendere decisioni sulla base di valori presenti nella tupla.
\paragraph{Clustering} L'obbiettivo del clustering è quello di suddividere i dati in gruppi omogenei detti \emph{cluster} in modo che i dati appartenenti allo stesso gruppo presentino attributi simili. In questo caso non abbiamo nessuna conoscenza pregressa sulle aggregazioni possibili. I cluster ottenuti possono essere sovrapposti e ordinati gerarchicamente.
